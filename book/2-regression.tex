\chapter{Regression}

% ---------- MAE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MAE}
\subsection{Mean Absolute Error}

MAE is one of the most popular regression accuracy metrics. It is calculated as the sum of absolute errors divided by the sample size. 
It is a scale-dependent accuracy measure which means that it uses the same scale as the data being measured.

% equation
\begin{center}
    \tikz{
        \node[inner sep=2pt, font=\Large] (a) {
            {
                $\displaystyle
                MAE = \frac{1}{{\color{nmlred}n}} \sum_{t=1}^n |{\color{nmlcyan}Y_t} - {\color{nmlpurple}\hat{Y}_t}|
                $
            }
        };
        \draw[-latex,nmlred, semithick] ($(a.south)+(-0.4,0.2)$) to[bend left=15] node[pos=1, left] {number of samples} +(-1,-.5);
        \draw[-latex,nmlpurple, semithick] ($(a.north)+(2.2,-0.3)$) to[bend left=15] node[pos=1, right] {forecast value} +(1,.5); 
        \draw[-latex,nmlcyan, semithick] ($(a.south)+(1.2,0.5)$) to[bend right=15] node[pos=1, right] {actual value} +(1,-.5);
    }
\end{center}

The smaller the MAE, the closer the model's predictions are to the actual targets.
Theoretically, MAE belongs in the 0 to +infinity range. One of the aspects that makes MAE popular is that it is easy to understand and compute.

\textbf{When to use MAE?}

Use MAE when you need an interpretable, robust metric that penalizes all errors equally.
Avoid using it when larger errors need more significant penalization.

% strength and weakness box
\coloredboxes{
    \item MAE provides an easy-to-understand value since it represents the average error in the same units as the data.
    \item MAE treats under-predictions and over-predictions equally. Bear in mind that this may not be desirable in all contexts.
}
{
    \item MAE can be biased when the distribution of errors is skewed, as it does not account for the direction of the error.
    \item The absolute value function used in MAE is not differentiable at zero, which can pose challenges in optimization
    and gradient-based learning algorithms.
}

\clearpage

\thispagestyle{customstyle}

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/MAE_3d_surface.png}
    % \caption{Caption}
\end{figure*}

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \vspace{-10pt} % Adjust vertical alignment if needed
    \includegraphics[width=0.45\textwidth]{figures/MAE_cross_section.png} % Your figure goes here
    \vspace{-10pt} % Adjust vertical alignment if needed
\end{wrapfigure}

% Left text with the image on the right
\textbf{Figure 3.1 MAE.} \underline{Top:} The rate of change of MAE is linear. 
Each error contributes proportionally to the total error. 
\underline{Right:} We can see that MAE is always non-negative, symmetrical,
and cantered around zero. By looking at this plot it is clear that MAE is not differentiable at zero.

\orangebox{Did you know that...}
{A forecast method that minimizes MAE
will lead to forecasts of the median.}


\textbf{Other related metrics}

Other metrics commonly explored alongside MAE are Mean Squared Error (MSE), Root Mean Squared Error (RMSE), 
and Mean Absolute Percentage Error (MAPE).

% ---------- MSE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MSE}
\subsection{Mean Squared Error}

MSE is a common metric to evaluate the performance of regression models and a popular loss optimization function. It measures the average of the squared errors.
The units of MSE are the squares of the predicted values, which can sometimes make interpretation challenging.

% equation
\begin{center}
[FORMULA GOES HERE]
\end{center}

The smaller the MSE, the closer the model's predictions are to the actual targets. Theoretically, MSE belongs in the 0 to +infinity range.
A common use of MSE as a loss function is in the least squares method.

\textbf{When to use MSE?}

Use MSE if having a few large mistakes is much worse than having many small ones. Otherwise, MAE might be a better metric.

% strength and weakness box
\coloredboxes{
    \item MSE is differentiable, which is useful in optimization algorithms that require gradient information, such as gradient descent.
}
{
    \item Due to the squaring of each error term, MSE is particularly sensitive to outliers. Large errors contribute more significantly to the MSE than smaller ones.
    \item Because it squares the differences, the metric can be harder to interpret, especially when dealing with units.
    Let's say you are forecasting revenue; MSE would measure your forecast accuracy in dollars-squared, a bit weird, right?
}

\clearpage

\thispagestyle{customstyle}

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/MSE_3d_surface.png}
    % \caption{Caption}
\end{figure*}

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \vspace{-10pt} % Adjust vertical alignment if needed
    \includegraphics[width=0.45\textwidth]{figures/MSE_cross_section.png} % Your figure goes here
    \vspace{-10pt} % Adjust vertical alignment if needed
\end{wrapfigure}

% Left text with the image on the right
\textbf{Figure 3.2 MSE.} \underline{Top:} MSE increases quadratically with the magnitude of the prediction error,
reflecting that larger errors contribute more significantly to the MSE.
\underline{Right:} MSE is always non-negative, symmetrical, and centered around 0.

\orangebox{Did you know that...}
{MSE can be written as the sum of the variance and bias of an estimator. $MSE(\hat{\theta}) = Var(\hat{\theta}) + \left(Bias(\hat{\theta})\right)^2$ which means
that if we are dealing with an unbiased estimators MSE is equivalent to the variance.}

\textbf{Other related metrics}

Other metrics that are commonly explored alongside MSE are Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).

% ---------- MSLE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MSLE}
\subsection{Mean Squared Log Error}

MSLE is a statistical measure used to evaluate the accuracy of a forecasting model.
It is commonly used when the data has a wide range of values.
It measures the average of the squared differences between the logarithms of the predicted and actual values.

% formula
\begin{center}
    [FORMULA GOES HERE]
\end{center}
    
MSLE is always a positive value, with a smaller MSLE indicating better forecast accuracy. Theoretically, MSLE belongs in the 0 to +infinity range.

\textbf{When to use MSLE?}

This metric is best used when targets have exponential growth, such as population counts or average sales of a commodity over a span of years.

% strength and weakness box
\coloredboxes{
    \item It handles large ranges of values. The logarithmic transformation helps manage large ranges of target values, which are common in real-world datasets.
}
{
    \item MSLE penalizes an under-predicted estimate more than an over-predicted estimate. This can be a strength in scenarios where underestimating a value can be more problematic than overestimating it.
    \item MSLE is not suitable for data with negative values or zero values, as the logarithm function is not defined for these values.
}

% ---------- RMSE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{RMSE}
\subsection{Root Mean Squared Error}

Similarly to MSE, RMSE squares the difference between predictions and true values but takes the square root of the mean.
Simplifying its interpretation units since the error is returned in the natural units of the data.

% formula
\begin{center}
    [FORMULA GOES HERE]
\end{center}

The RMSE is always a positive value, with a smaller RMSE indicating better forecast accuracy.
Theoretically, RMSE belongs in the 0 to +infinity range. By squaring the differences, RMSE gives more weight to larger errors, making it sensitive to outliers.

\textbf{When to use RMSE?}
Use RMSE when you need a metric that penalizes larger errors more than smaller ones due to the squaring of the residuals and reports an
interpretable value in the same units as the target variable.

% strength and weakness box
\coloredboxes{
    \item Because RMSE is measured in the same units as the target variable, interpreting its magnitude is straightforward.
    \item The squaring of the errors ensures that larger errors have a greater impact on the RMSE value, which can be beneficial when large errors are particularly undesirable.
}
{
    \item Unlike some other metrics like R-squared and MAPE, RMSE does not provide a normalized measure, making it difficult to compare across different datasets without standardization.
}

% ---------- RMSLE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{RMSLE}
\subsection{Root Mean Squared Log Error}

RMSLE is a variation of the RMSE metric that is particularly useful when dealing with targets that have a wide range of values, such as those with an exponential growth pattern.
It measures the square root of the average of the squared logarithmic errors.

% formula
\begin{center}
    [FORMULA GOES HERE]
\end{center}

RMSLE is always a positive value, with a smaller RMSLE indicating better forecast accuracy. Theoretically, RMSLE belongs in the 0 to +infinity range.
By using the logarithm, RMSLE dampens the effect of large outliers compared to RMSE.

\textbf{When to use RMSLE?}
RMSLE is best used when the target variables have a large range and an exponential growth pattern, such as population counts or sales figures over time.
It can be more appropriate than RMSE in these cases as it is less sensitive to large outliers.

% strength and weakness box
\coloredboxes{
    \item Handles large ranges of values well due to the logarithmic transformation.
    \item RMSLE penalizes underestimation more than overestimation, which can be beneficial in some use cases.
}
{
    \item RMSLE is not suitable for data with negative values or zero values, as the logarithm function is not defined for these.
    \item Interpretation can be less intuitive than RMSE, as the final value is in logarithmic scale.
}

% ---------- MAPE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MAPE}
\subsection{Mean Absolute Percentage Error}

MAPE is one of the most widely used measures of forecast accuracy due to its scale independence and interoperability.
It is derived from the Mean Absolute Error (MAE), adjusted to provide a percentage measure, making it easier to interpret and compare across different datasets and contexts.

% formula
\begin{center}
    [FORMULA GOES HERE]
\end{center}

When the forecasted values $\hat{Y_{t}}$ are equal to the actual values $Y_{t}$ for all data points, MAPE is 0\% indicating a perfect forecast with no error.
However, when the relationship between the actual values and predicted values are very different, the percentage error becomes extremely large.

\textbf{When to use MAPE?}

MAPE is useful when the value of the error on it's own is not as important as its relative magnitude compared to the actual target values.
It is not feasible when actual values can be 0. Additionally, MAPE is beneficial when it serves as a meaningful business metric.

% strength and weakness box
\coloredboxes{
    \item Scale-independent and easy interpretation as a percentage error.
}
{
    \item Undefined when $Y_{t} = 0$
    \item MAPE penalizes negative errors $(\hat{Y_{t}} > Y)$ more than positive errors. This makes it biased since, optimizing for MAPE systematically selects the method with lower forecasts.
}

\clearpage

\thispagestyle{customstyle}

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/MAPE_3d_surface.png}
    % \caption{Caption}
\end{figure*}

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \vspace{-10pt} % Adjust vertical alignment if needed
    \includegraphics[width=0.45\textwidth]{figures/MAPE_cross_section.png} % Your figure goes here
    \vspace{-10pt} % Adjust vertical alignment if needed
\end{wrapfigure}


% Left text with the image on the right
\textbf{Figure 3.2 MSE.} Illustrates the drawbacks of MAPE. It produces extremely large values (red area) when the relationship between
targets and predicted values is significantly different. \underline{Top:} The rate of change of MAPE is non-linear.
\underline{Right:} Clearly shows MAPE's asymmetry in relation to over- and under-predicting the target variable when optimizing for MAPE.

\orangebox{Did you know that...}
{MAPE is not translation invariant. This means that if we add a constant to all actual and prediction values, the error will be different.
In math terms, it means that $MAPE(Y_{t} + c, \hat{Y_{t}} + c) \not= MAPE(Y_{t}, \hat{Y_{t}})$ , where $c$ is a constant.}


\textbf{Other related metrics}
To overcome these issues with MAPE, there are some other measures proposed in the literature: Mean Absolute Scaled Error (MASE),
Symmetric Mean Absolute Percentage Error (sMAPE), Mean Directional Accuracy (MDA), Mean Arctangent Absolute Percentage Error (MAAPE).

% ---------- sMAPE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{sMAPE}
\subsection{Symmetric Mean Absolute Percentage Error}

sMAPE is a variant of the popular metric MAPE and addresses some of its shortcomings. Unlike MAPE, sMAPE has both a lower and an upper bound and is also better
at handling data with target values that can be zero.

% formula
\begin{center}
    [FORMULA GOES HERE]
\end{center}

sMAPE ranges from 0\% to 200\%, with 0\% indicating a perfect forecast and 200\% indicating the worst possible forecast. There is another sMAPE version without the factor of 0.5 in the denominator, which makes the metric range between 0\% and 100\%.

\textbf{When to use sMAPE?}

sMAPE is a good choice when you want some of the benefits of MAPE, like percentage interpretation, but don't want its shortcomings like producing extremely large values when the relationship between
targets and predicted values are very different.

% strength and weakness box
\coloredboxes{
    \item Can handle target values equal to zero.
    \item Has both a lower and an upper bound.
}
{
    \item Undefined when $|Y_{t}| = |\hat{Y_{t}}| = 0$
    \item sMAPE is not symmetric to over- and under-forecasts. For example, if $Y_{t} = 100$ and in one case we have $\hat{Y_{t}} = 90$, this gives ansMAPE of 4.76\%; whereas if $\hat{Y_{t}} = 110$, then the sMAPE would be 5.26\%.
}


% ---------- wMAPE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{wMAPE}
\subsection{Weighted Mean Absolute Percentage Error}

% ---------- MASE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MASE}
\subsection{Mean Absolute Scaled Error}

% ---------- MSPE ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MSPE}
\subsection{Mean Squared Prediction Error}

% ---------- MDA ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MDA}
\subsection{Mean Directional Accuracy}

% ---------- MAD ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MAD}
\subsection{Mean Absolute Deviation}

% ---------- MPD ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MPD}
\subsection{Mean Poisson Deviance}

% ---------- MGD ----------
\clearpage
\thispagestyle{regressionstyle}
\section{MGD}
\subsection{Mean Gamma Deviance}

% ---------- R-squared ----------
\clearpage
\section{$\mathbf{R^2}$}
\subsection{R-squared}
\thispagestyle{regressionstyle}

R-squared needs little introduction; it's featured in every statistics book. Also known as the coefficient of determination, it's commonly introduced as a measure that quantifies the amount of variability explained by the regression model.

\begin{center}
    \tikz{
        \node[inner sep=2pt, font=\Large] (a) {
            {
                $\displaystyle
                R^2 = 1 - \frac{\sum_{t=1}^n (Y_t - {\color{nmlpurple}\hat{Y}_t})^2}{\sum_{t=1}^n ({\color{nmlcyan}Y_t} - {\color{teal!70!green}\bar{Y}})^2}
                $
            }
        };
        
        \draw[-latex,nmlpurple, semithick] ($(a.north)+(2.1,0)$) to[bend left=15] node[pos=1, right] {Predicted value} +(1,.5); 
        \draw[-latex,teal!70!green, semithick] ($(a.south)+(2.1,0.1)$) to[bend right=15] node[pos=1, right] {Mean of targets} +(1,-.5); 
        \draw[-latex,nmlcyan, semithick] ($(a.south)+(1,0.1)$) to[bend left=15] node[pos=1, left] {Target value} +(-1,-.5); 
    }
\end{center}

However, it may be easier to think of R-squared as a way to scale MSE between a perfect model and one that always predicts the mean. A score of 1.0 means $Y_t$ and $\hat{Y}_t$ are equal. Despite its name, R-squared can be negative if the model performs worse than just predicting the mean.

\textbf{When to use R-squared?}

R-squared can be more intuitive than MAE, MSE, RMSE, and other scale-dependent metrics since it can be expressed as a percentage, whereas the latter have arbitrary ranges.

\coloredboxes{
    \item Easy Interpretation. Especially when interpreted as a scaled MSE.
    \item R-squared is widely accepted in statistical analysis and research, making it a standard choice for evaluating model performance.
}
{
    \item Just like MSE, R-squared can be sensitive to outliers, as large errors have a greater impact.
    \item Be cautious about which value of $\bar{Y}$ to use. Most implementations default to $\bar{Y}_{\text {test }}$ which can lead to information leakage. It is advisable to use $\bar{Y}_{\text {train }}$ instead.
}


\clearpage
\thispagestyle{customstyle}


\begin{figure*}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/R2_explained.png}
    % \caption{Caption}
    \label{fig1}
\end{figure*}

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \vspace{-10pt} % Adjust vertical alignment if needed
    \includegraphics[width=0.45\textwidth]{figures/R2_3d_surface.png} % Your figure goes here
    \vspace{-10pt} % Adjust vertical alignment if needed
\end{wrapfigure}

% Left text with the image on the right
\textbf{Figure 2.15 R-Squared.} \underline{Top:} The
areas of the purple squares
represent the MSE of the
evaluated model. While, the areas
of the red squares represent the
MSE of a model that always
predicts the mean. R-squared
can be written as $R^2 = 1-\frac{\color{violet!50}MSE_{model}}{\color{nmlred}MSE_{baseline}}$\\
\underline{Right:} R-squared quickly drops
into the negative region in cases
where the mean is a better
predictor than the evaluated
model.


\orangebox{%
Did you know that...}
{
R-squared is more than 100 years old; it was introduced by geneticist Sewall Wright in 1921.
}


\textbf{R-squared alternatives and related metrics}

Other metrics commonly explored alongside R-squared are Adjusted Rsquared, out-of-sample R-squared,
Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), etc.



% ---------- D2 ----------
\clearpage
\thispagestyle{regressionstyle}
\section{D2}
\subsection{D2 Absolute Score}

% ---------- Explained Variance Score ----------
\clearpage
\thispagestyle{regressionstyle}
\section{Explained Variance Score}
\subsection{Explained Variance Score}